[2023-07-13 18:49:10] COMMAND: main.py --model-name ada --log-file ./results/openai_models/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de --few-shot
[2023-07-13 18:49:10] Arguments: {'model_name': 'ada', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai_models/thruthfullqa_en_de.txt', 'few_shot': True, 'lang_pair': 'en-de'}
[2023-07-13 18:49:10] start experiment...
[2023-07-13 18:49:10] language pair: English-German
[2023-07-13 18:49:10] model parameters: 350M
bleu score: 7.56|language acc:0.981640146878825|question mark acc:0.6658506731946144
[2023-07-13 18:58:05] ====================
[2023-07-13 18:58:09] COMMAND: main.py --model-name babbage --log-file ./results/openai_models/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de --few-shot
[2023-07-13 18:58:09] Arguments: {'model_name': 'babbage', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai_models/thruthfullqa_en_de.txt', 'few_shot': True, 'lang_pair': 'en-de'}
[2023-07-13 18:58:09] start experiment...
[2023-07-13 18:58:09] language pair: English-German
[2023-07-13 18:58:09] model parameters: 1.3B
[2023-07-13 19:07:30] bleu score: 10.43|language acc:0.8996328029375765|question mark acc:0.6401468788249693
[2023-07-13 19:07:30] ====================
[2023-07-13 19:07:34] COMMAND: main.py --model-name curie --log-file ./results/openai_models/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de --few-shot
[2023-07-13 19:07:34] Arguments: {'model_name': 'curie', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai_models/thruthfullqa_en_de.txt', 'few_shot': True, 'lang_pair': 'en-de'}
[2023-07-13 19:07:34] start experiment...
[2023-07-13 19:07:34] language pair: English-German
[2023-07-13 19:07:34] model parameters: 6.7B
[2023-07-13 19:16:47] bleu score: 21.28|language acc:0.981640146878825|question mark acc:0.8861689106487148
[2023-07-13 19:16:47] ====================
[2023-07-13 19:42:32] COMMAND: main.py --model-name davinci --log-file ./results/openai_models/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de --few-shot
[2023-07-13 19:42:32] Arguments: {'model_name': 'davinci', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai_models/thruthfullqa_en_de.txt', 'few_shot': True, 'lang_pair': 'en-de'}
[2023-07-13 19:42:32] start experiment...
[2023-07-13 19:42:32] language pair: English-German
[2023-07-13 19:42:32] model parameters: 175B
[2023-07-13 19:52:10] bleu score: 31.77|language acc:0.98531211750306|question mark acc:0.835985312117503
[2023-07-13 19:52:10] ====================

[2023-07-08 22:24:17] COMMAND: main.py --model-name gpt-3.5-turbo --log-file ./results/openai_models/results/thruthfullqa.txt --dataset ./datasets/truthfullqa/en_de.df
[2023-07-08 22:24:17] Arguments: {'model_name': 'gpt-3.5-turbo', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai_models/results/thruthfullqa.txt'}
[2023-07-08 22:24:17] start experiment...
[2023-07-08 22:24:17] language pair: English-German
[2023-07-08 22:24:17] model parameters: 175B
[2023-07-08 22:35:35] bleu score: 41.54|language acc:0.9914320685434517|question mark acc:0.9938800489596084
====================
[2023-07-08 19:52:12] COMMAND: main.py --model-name text-davinci-003 --log-file .results/openai_models/thruthfullqa.txt --dataset datasets/truthfullqa/en_de.df
[2023-07-08 19:52:12] Arguments: {'model_name': 'text-davinci-003', 'dataset': 'datasets/truthfullqa/en_de.df', 'log_file': '.results/openai_models/thruthfullqa.txt'}
[2023-07-08 19:52:12] start experiment...
[2023-07-08 19:52:12] language pair: English-German
[2023-07-08 19:52:12] model parameters: 175B
datasets/truthfullqa/en_de_output/text-davinci-003.txt
[2023-07-08 20:07:02] [2023-07-12 16:25:48] bleu score: 40.12|language acc:0.9902080783353733|question mark acc:0.9326805385556916
[2023-07-08 22:24:09] ====================
[2023-07-08 19:43:35] COMMAND: main.py --model-name text-davinci-002 --log-file .results/openai_models/thruthfullqa.txt --dataset datasets/truthfullqa/en_de.df
[2023-07-08 19:43:35] Arguments: {'model_name': 'text-davinci-002', 'dataset': 'datasets/truthfullqa/en_de.df', 'log_file': '.results/openai_models/thruthfullqa.txt'}
[2023-07-08 19:43:35] start experiment...
[2023-07-08 19:43:35] language pair: English-German
[2023-07-08 19:43:35] model parameters: 175B
datasets/truthfullqa/en_de_output/text-davinci-002.txt
[2023-07-08 19:52:09] bleu score: 37.38|language acc:0.9547123623011016|question mark acc:0.7882496940024479
======================
[2023-07-17 20:46:30] COMMAND: main.py --model-name text-ada-001 --log-file ./results/openai/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de
[2023-07-17 20:46:30] Arguments: {'model_name': 'text-ada-001', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai/thruthfullqa_en_de.txt', 'few_shot': False, 'lang_pair': 'en-de'}
[2023-07-17 20:46:30] start experiment...
[2023-07-17 20:46:30] language pair: English-German
[2023-07-17 20:46:30] model parameters: 350M
[2023-07-17 20:51:36] bleu score: 0.45|language acc:0.0|question mark acc:0.4369645042839657
[2023-07-17 20:51:36] ====================
[2023-07-17 21:02:43] COMMAND: main.py --model-name text-babbage-001 --log-file ./results/openai/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de
[2023-07-17 21:02:43] Arguments: {'model_name': 'text-babbage-001', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai/thruthfullqa_en_de.txt', 'few_shot': False, 'lang_pair': 'en-de'}
[2023-07-17 21:02:43] start experiment...
[2023-07-17 21:02:43] language pair: English-German
[2023-07-17 21:02:43] model parameters: 1.3B
[2023-07-17 21:07:34] bleu score: 1.75|language acc:0.0|question mark acc:0.6988984088127295
[2023-07-17 21:07:34] ====================
[2023-07-17 21:07:38] COMMAND: main.py --model-name text-curie-001 --log-file ./results/openai_models/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de
[2023-07-17 21:07:38] Arguments: {'model_name': 'text-curie-001', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai_models/thruthfullqa_en_de.txt', 'few_shot': False, 'lang_pair': 'en-de'}
[2023-07-17 21:07:38] start experiment...
[2023-07-17 21:07:38] language pair: English-German
[2023-07-17 21:07:38] model parameters: 6.7B
[2023-07-17 21:14:22] bleu score: 12.18|language acc:0.0|question mark acc:0.4847001223990208
[2023-07-17 21:14:22] ====================
[2023-07-17 21:14:25] COMMAND: main.py --model-name text-davinci-001 --log-file ./results/openai_models/thruthfullqa_en_de.txt --dataset ./datasets/truthfullqa/en_de.df --lang-pair en-de
[2023-07-17 21:14:25] Arguments: {'model_name': 'text-davinci-001', 'dataset': './datasets/truthfullqa/en_de.df', 'log_file': './results/openai_models/thruthfullqa_en_de.txt', 'few_shot': False, 'lang_pair': 'en-de'}
[2023-07-17 21:14:25] start experiment...
[2023-07-17 21:14:25] language pair: English-German
[2023-07-17 21:14:25] model parameters: 175B
[2023-07-17 21:22:36] bleu score: 19.80|language acc:0.0|question mark acc:0.594859241126071
